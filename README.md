<h2>Event Extraction Papers </h2>



<ul>

                             

 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(1).pdf" style="text-decoration:none;">Attend and Attack: Attention Guided Adversarial Attacks on Visual Question Answering Models</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(2).pdf" style="text-decoration:none;">Multimodal Medical Image Retrieval based on Latent Topic Modeling</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(3).pdf" style="text-decoration:none;">Unifying and Merging Well-trained Deep Neural Networks for Inference Stage</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(4).pdf" style="text-decoration:none;">Semi-Supervised Multimodal Deep Learning for RGB-D Object Recognition</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(5).pdf" style="text-decoration:none;">Microsoft COCO: Common Objects in Context</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(6).pdf" style="text-decoration:none;">Deep Fragment Embeddings for Bidirectional Image Sentence Mapping</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(7).pdf" style="text-decoration:none;">Show and Tell: A Neural Image Caption Generator</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(8).pdf" style="text-decoration:none;"> Deep Visual-Semantic Alignments for Generating Image Descriptions </a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(9).pdf" style="text-decoration:none;">A Dataset for Movie Description</a></li>
  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(10).pdf" style="text-decoration:none;">Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(11).pdf" style="text-decoration:none;">What's Cookin'? Interpreting Cooking Videos using Text, Speech and Vision</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(12).pdf" style="text-decoration:none;">VQA: Visual Question Answering</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(13).pdf" style="text-decoration:none;">Building a Large-scale Multimodal Knowledge Base System for Answering Visual Queries</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(14).pdf" style="text-decoration:none;">Multimodal Deep Learning for Robust RGB-D Object Recognition</a></li>
                              
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(15).pdf" style="text-decoration:none;">Order-Embeddings of Images and Language</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(16).pdf" style="text-decoration:none;">VisualWord2Vec (vis-w2v): Learning Visually Grounded Word Embeddings Using Abstract Scenes</a></li>

  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(17).pdf" style="text-decoration:none;">MovieQA: Understanding Stories in Movies through Question-Answering</a></li>   
  
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(18).pdf" style="text-decoration:none;">Hollywood in Homes: Crowdsourcing Data
Collection for Activity Understanding</a></li> 

  
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(19).pdf" style="text-decoration:none;">Generative Adversarial Text to Image Synthesis</a></li> 

<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(20).pdf" style="text-decoration:none;">Learning to Communicate with
Deep Multi-Agent Reinforcement Learning</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(21).pdf" style="text-decoration:none;">Review Networks for Caption Generation</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(22).pdf" style="text-decoration:none;">Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings</a></li> 
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(23).pdf" style="text-decoration:none;">Towards Transparent AI Systems:
Interpreting Visual Question Answering Models</a></li> 
 

   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(24).pdf" style="text-decoration:none;">Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning Challenge</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(25).pdf" style="text-decoration:none;">SoundNet: Learning Sound
Representations from Unlabeled Video</a></li>                              
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(26).pdf" style="text-decoration:none;">Visual Dialog</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(27).pdf" style="text-decoration:none;">Multi-Agent Cooperation and the Emergence of (Natural) Language</a></li>
   
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(28).pdf" style="text-decoration:none;">Deep Voice: Real-time Neural Text-to-Speech</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(29).pdf" style="text-decoration:none;">Zero-Shot Learning - The Good, the Bad and the Ugly </a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(30).pdf" style="text-decoration:none;">Emergence of Grounded Compositional Language in Multi-Agent Populations</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(31).pdf" style="text-decoration:none;">Learning Robust Visual-Semantic Embeddings</a></li> 
    <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(32).pdf" style="text-decoration:none;">Learning Cooperative Visual Dialog Agents with Deep Reinforcement Learning</a></li> 

   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(33).pdf" style="text-decoration:none;">Towards Building Large Scale Multimodal Domain-Aware Conversation Systems</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(34).pdf" style="text-decoration:none;">Generating Descriptions with Grounded and Co-Referenced People</a></li> 
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(35).pdf" style="text-decoration:none;">Deep Multimodal Representation Learning from Temporal Data</a></li> 

  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(36).pdf" style="text-decoration:none;">Learning to Reason: End-to-End Module Networks for Visual Question Answering</a></li> 
 
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(37).pdf" style="text-decoration:none;">End-to-End Multimodal Emotion Recognition using Deep Neural Networks</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(38).pdf" style="text-decoration:none;">Deep Voice 2: Multi-Speaker Neural Text-to-Speech</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(39).pdf" style="text-decoration:none;">Gated-Attention Architectures for Task-Oriented Language Grounding</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(40).pdf" style="text-decoration:none;">Natural Language Does Not Emerge 'Naturally' in Multi-Agent Dialog</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(41).pdf" style="text-decoration:none;">SCAN: Learning Hierarchical Compositional Visual Concepts</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(42).pdf" style="text-decoration:none;">Tensor Fusion Network for Multimodal Sentiment Analysis</a></li>
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(43).pdf" style="text-decoration:none;">Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(44).pdf" style="text-decoration:none;">Localizing Moments in Video with Natural Language</a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(45).pdf" style="text-decoration:none;">Answering Visual-Relational Queries in Web-Extracted Knowledge Graphs</a></li>  
   
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(46).pdf" style="text-decoration:none;">Cross-modal Recurrent Models for Weight Objective Prediction from Multimodal Time-series Data</a></li> 
                             
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(47).pdf" style="text-decoration:none;">Fooling Vision and Language Models
Despite Localization and Attention Mechanism</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(48).pdf" style="text-decoration:none;">Emergent Translation in Multi-Agent Communication</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(49).pdf" style="text-decoration:none;">Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning</a></li>
                              
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(50).pdf" style="text-decoration:none;">Multimodal Probabilistic Model-Based Planning for Human-Robot Interaction</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(51).pdf" style="text-decoration:none;">Learning Multi-ModalWord Representation Grounded in Visual Context</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(52).pdf" style="text-decoration:none;">Look, Imagine and Match:
Improving Textual-Visual Cross-Modal Retrieval with Generative Models</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(53).pdf" style="text-decoration:none;">Neural Motifs: Scene Graph Parsing with Global Context</a></li>
 
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(54).pdf" style="text-decoration:none;">Vision-and-Language Navigation: Interpreting visually-grounded navigation instructions in real environments </a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(55).pdf" style="text-decoration:none;">Video Captioning via Hierarchical Reinforcement Learning</a></li>
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(56).pdf" style="text-decoration:none;">Embodied Question Answering </a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(57).pdf" style="text-decoration:none;">Don't Just Assume; Look and Answer:
Overcoming Priors for Visual Question Answering</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(58).pdf" style="text-decoration:none;">Grounding Referring Expressions in Images by Variational Context</a></li>
    <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(59).pdf" style="text-decoration:none;">Attacking Visual Language Grounding with Adversarial Examples: A Case Study on Neural Image Captioning</a></li>
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(60).pdf" style="text-decoration:none;">Semi-supervised Multimodal Hashing </a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(61).pdf" style="text-decoration:none;"> Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(62).pdf" style="text-decoration:none;">Zero-Resource Neural Machine Translation with Multi-Agent Communication Game</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(63).pdf" style="text-decoration:none;">A probabilistic framework for multi-view feature learning with many-to-many associations via neural networks</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(64).pdf" style="text-decoration:none;">Multimodal Generative Models for Scalable Weakly-Supervised Learning</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(65).pdf" style="text-decoration:none;">Learning to Count Objects in Natural Images for Visual Question Answering </a></li> 

   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(66).pdf" style="text-decoration:none;">Multimodal Explanations: Justifying Decisions and Pointing to the Evidence</a></li> 
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(67).pdf" style="text-decoration:none;">Joint Event Detection and Description in Continuous Video Streams</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(68).pdf" style="text-decoration:none;">Learning the Joint Representation of Heterogeneous Temporal Events for Clinical Endpoint Prediction</a></li> 
 
  
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(69).pdf" style="text-decoration:none;">Look Before You Leap:
Bridging Model-Free and Model-Based Reinforcement Learning for Planned-Ahead Vision-and-Language Navigation</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(70).pdf" style="text-decoration:none;">Datasheets for Datasets</a></li> 
  
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(71).pdf" style="text-decoration:none;">Neural Baby Talk</a></li>
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(72).pdf" style="text-decoration:none;">Interpretable and Globally Optimal Prediction for Textual Grounding using Image Concepts</a></li> 
 
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(73).pdf" style="text-decoration:none;">Seeing Voices and Hearing Faces: Cross-modal biometric matching</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(74).pdf" style="text-decoration:none;">Jointly Discovering Visual Objects and SpokenWords from Raw Sensory Input</a></li>
    <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(75).pdf" style="text-decoration:none;">Image Generation from Scene Graphs</a></li>                        
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(76).pdf" style="text-decoration:none;">Multilevel Language and Vision Integration for Text-to-Clip Retrieval</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(77).pdf" style="text-decoration:none;">Learning to Color from Language</a></li> 
 
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(78).pdf" style="text-decoration:none;">Attention Based Natural Language Grounding by Navigating Virtual Environment</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(79).pdf" style="text-decoration:none;">No Metrics Are Perfect:
Adversarial Reward Learning for Visual Storytelling</a></li>


 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(80).pdf" style="text-decoration:none;">Multi-modal Approach for Affective Computing</a></li> 
 
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(81).pdf" style="text-decoration:none;">Charades-Ego: A Large-Scale Dataset of Paired Third and First Person Videos</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(82).pdf" style="text-decoration:none;">Dialog-based Interactive Image Retrieval</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(83).pdf" style="text-decoration:none;">Multimodal Hierarchical Reinforcement Learning Policy for Task-Oriented Visual Dialog</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(84).pdf" style="text-decoration:none;">Using Syntax to Ground Referring Expressions in Natural Images</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(85).pdf" style="text-decoration:none;">Efficient Low-rank Multimodal Fusion with Modality-Specific Factors</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(86).pdf" style="text-decoration:none;">Learning Factorized Multimodal Representations</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(87).pdf" style="text-decoration:none;">Talk the Walk: Navigating New York City through Grounded Dialogue</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(88).pdf" style="text-decoration:none;">Evolving Multimodal Robot Behavior via Many Stepping Stones with the Combinatorial Multi-Objective Evolutionary Algorithm</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(89).pdf" style="text-decoration:none;">Disjoint Mapping Network for Cross-modal Matching of Voices and Faces</a></li>
  
  
  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(90).pdf" style="text-decoration:none;"> Multimodal Language Analysis with Recurrent Multistage Fusion</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(91).pdf" style="text-decoration:none;">Mapping Instructions to Actions in 3D Environments with Visual Goal Prediction</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(92).pdf" style="text-decoration:none;">RecipeQA: A Challenge Dataset for Multimodal Comprehension of Cooking Recipes</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(93).pdf" style="text-decoration:none;"> Embedding Multimodal Relational Data for Knowledge Base Completion</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(94).pdf" style="text-decoration:none;">Visual Coreference Resolution in Visual Dialog using Neural Module Networks</a></li> 
  
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(95).pdf" style="text-decoration:none;">Deep Audio-Visual Speech Recognition</a></li>  
  
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(96).pdf" style="text-decoration:none;">From Audio to Semantics: Approaches to end-to-end spoken language understanding</a></li> 
  
  
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(97).pdf" style="text-decoration:none;">Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding</a></li>


 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(98).pdf" style="text-decoration:none;">MELD: A Multimodal Multi-Party Dataset
for Emotion Recognition in Conversations</a></li> 
  
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(99).pdf" style="text-decoration:none;">Overcoming Language Priors in Visual Question Answering with Adversarial Regularization</a></li>  
  
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(100).pdf" style="text-decoration:none;">Model Cards for Model Reporting</a></li>  
  
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(101).pdf" style="text-decoration:none;">Making Sense of Vision and Touch: Self-Supervised Learning of Multimodal Representations for Contact-Rich Tasks</a></li> 
  
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(102).pdf" style="text-decoration:none;">Do Explanations make VQA Models more Predictable to a Human?</a></li> 
  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(103).pdf" style="text-decoration:none;">Latent Variable Model for Multi-modal Translation </a></li> 
  
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(104).pdf" style="text-decoration:none;">COMMONSENSEQA: A Question Answering Challenge Targeting Commonsense Knowledge</a></li>  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(105).pdf" style="text-decoration:none;">Unsupervised Multimodal Representation Learning across Medical Images and Reports</a></li> 
 
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(106).pdf" style="text-decoration:none;">EARLY FUSION for Goal Directed Robotic Vision</a></li> 
  
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(107).pdf" style="text-decoration:none;">Reinforced Cross-Modal Matching and Self-Supervised Imitation Learning for Vision-Language Navigation</a></li> 
  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(108).pdf" style="text-decoration:none;">Show, Control and Tell:
A Framework for Generating Controllable and Grounded Captions</a></li> 
  
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(109).pdf" style="text-decoration:none;">From Recognition to Cognition: Visual Commonsense Reasoning</a></li>  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(110).pdf" style="text-decoration:none;">Improving Hospital Mortality Prediction with Medical Named Entities and Multimodal Learning </a></li>  
   
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(111).pdf" style="text-decoration:none;">TOUCHDOWN: Natural Language Navigation and Spatial Reasoning in Visual Street Environments</a></li> 
  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(112).pdf" style="text-decoration:none;">Multi-task Learning of Hierarchical Vision-Language Representation</a></li> 
  
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(113).pdf" style="text-decoration:none;">Knowledge-driven generative subspaces for modeling multi-view dependencies in medical data</a></li>  
   
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(114).pdf" style="text-decoration:none;">Multimodal Explanations by Predicting Counterfactuality in Videos</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(115).pdf" style="text-decoration:none;">Grounded Video Description</a></li>  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(116).pdf" style="text-decoration:none;">Found in Translation:
Learning Robust Joint Representations by Cyclic Translations Between Modalities</a></li>   
   
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(117).pdf" style="text-decoration:none;">Self-Supervised Learning from Web Data for Multimodal Retrieval</a></li>  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(118).pdf" style="text-decoration:none;">Self-Monitoring Navigation Agent via Auxiliary Progress Estimation</a></li>  
   
  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(119).pdf" style="text-decoration:none;">Evaluating Text-to-Image Matching using Binary Image Selection (BISON)</a></li> 
  
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(120).pdf" style="text-decoration:none;">Read, Watch, and Move: Reinforcement Learning for Temporally Grounding Natural Language Descriptions in Videos</a></li>  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(121).pdf" style="text-decoration:none;">Embodied Multimodal Multitask Learning</a></li>   
   
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(122).pdf" style="text-decoration:none;">Simultaneously Learning Vision and Feature-based Control Policies for Real-world Ball-in-a-Cup</a></li>  
     
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(123).pdf" style="text-decoration:none;">From Language to Goals: Inverse Reinforcement Learning for Vision-Based Instruction Following</a></li>  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(124).pdf" style="text-decoration:none;">Audio-Linguistic Embeddings for Spoken Sentences</a></li>   
   
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(125).pdf" style="text-decoration:none;">Probabilistic Neural-symbolic Models for Interpretable Visual Question Answering</a></li>   
   
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(126).pdf" style="text-decoration:none;">
Audio Caption: Listen and Tell</a></li> 
   
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(127).pdf" style="text-decoration:none;">GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question Answering</a></li>  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(128).pdf" style="text-decoration:none;">The Regretful Agent: Heuristic-Aided Navigation through Progress Estimation</a></li>   
   
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(129).pdf" style="text-decoration:none;">Tactical Rewind: Self-Correction via Backtracking in Vision-and-Language Navigation</a></li>   
   
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(130).pdf" style="text-decoration:none;">Neural Language Modeling with Visual Features </a></li>    
   
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(131).pdf" style="text-decoration:none;">Learning to Speak and Act in a Fantasy Text Adventure Game</a></li>   
   
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(132).pdf" style="text-decoration:none;">On the Pitfalls of Measuring Emergent Communication</a></li>   
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(133).pdf" style="text-decoration:none;">MMKG: Multi-Modal Knowledge Graphs</a></li>     
   
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(134).pdf" style="text-decoration:none;">MFAS: Multimodal Fusion Architecture Search</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(135).pdf" style="text-decoration:none;">Wav2Pix: Speech-conditioned Face Generation using Generative Adversarial Networks</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(136).pdf" style="text-decoration:none;">Video Relationship Reasoning using Gated Spatio-Temporal Energy Graph</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(137).pdf" style="text-decoration:none;">Habitat: A Platform for Embodied AI Research</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(138).pdf" style="text-decoration:none;">VideoBERT: A Joint Model for Video and Language Representation Learning</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(139).pdf" style="text-decoration:none;">VATEX: A Large-Scale, High-Quality Multilingual Dataset for Video-and-Language Research</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(140).pdf" style="text-decoration:none;">Black is to Criminal as Caucasian is to Police: Detecting and Removing Multiclass Bias inWord Embeddings</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(141).pdf" style="text-decoration:none;"> From Semi-supervised to Almost-unsupervised Speech Recognition with Very-low Resource by Jointly Learning Phonetic Structures from Audio and Text Embeddings</a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(142).pdf" style="text-decoration:none;">Temporal Cycle-Consistency Learning</a></li>                             
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(143).pdf" style="text-decoration:none;">Emergence of Compositional Language with Deep Generational Transmission</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(144).pdf" style="text-decoration:none;">SOCIAL IQA: Commonsense Reasoning about Social Interactions</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(145).pdf" style="text-decoration:none;">The Neuro-Symbolic Concept Learner: Interpreting Scenes, Words, and Sentences From Natural Supervision</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(146).pdf" style="text-decoration:none;">Speech2Face: Learning the Face Behind a Voice</a></li>
                              
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(147).pdf" style="text-decoration:none;">Reconstructing faces from voices</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(148).pdf" style="text-decoration:none;">Leveraging Medical Visual Question Answering with Supporting Facts</a></li>

  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(149).pdf" style="text-decoration:none;">Stay on the Path: Instruction Fidelity in Vision-and-Language Navigation</a></li>   
  
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(150).pdf" style="text-decoration:none;">What Makes Training Multi-modal Classification Networks Hard?</a></li> 

<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(151).pdf" style="text-decoration:none;">Factorized Inference in Deep Markov Models for Incomplete Multimodal Time Series </a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(152).pdf" style="text-decoration:none;">OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge </a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(153).pdf" style="text-decoration:none;">Multimodal Transformer for Unaligned Multimodal Language Sequences</a></li> 
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(154).pdf" style="text-decoration:none;">Are You Looking? Grounding to Multiple Modalities in Vision-and-Language Navigation</a></li> 
 

   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(155).pdf" style="text-decoration:none;">Hierarchical Decision Making by Generating and Following Natural Language Instructions</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(156).pdf" style="text-decoration:none;">Learning Representations by Maximizing Mutual Information Across Views</a></li>                              
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(157).pdf" style="text-decoration:none;">Exploring Phoneme-Level Speech Representations for End-to-End Speech Translation</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(158).pdf" style="text-decoration:none;">Learning to Compose and Reason with
Language Tree Structures for Visual Grounding</a></li>
   
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(159).pdf" style="text-decoration:none;">Towards Multimodal Sarcasm Detection
(An Obviously Perfect Paper) </a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(160).pdf" style="text-decoration:none;">Learning Individual Styles of Conversational Gesture</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(161).pdf" style="text-decoration:none;">Lattice Transformer for Speech Translation</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(162).pdf" style="text-decoration:none;">Learning Video Representations using Contrastive Bidirectional Transformer</a></li> 
    <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(163).pdf" style="text-decoration:none;">Language as an Abstraction
for Hierarchical Deep Reinforcement Learning </a></li> 

   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(164).pdf" style="text-decoration:none;">Distilling Translations with Visual Awareness</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(165).pdf" style="text-decoration:none;">RUBi: Reducing Unimodal Biases
for Visual Question Answering</a></li> 
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(166).pdf" style="text-decoration:none;">Learning Representations from Imperfect Time Series Data via Tensor Rank Regularization</a></li> 

  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(167).pdf" style="text-decoration:none;">Language2Pose: Natural Language Grounded Pose Forecasting</a></li> 
 
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(168).pdf" style="text-decoration:none;">Vision-and-Dialog Navigation</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(169).pdf" style="text-decoration:none;">OmniNet: A unified architecture for multi-modal multi-task learning</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(170).pdf" style="text-decoration:none;">ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(171).pdf" style="text-decoration:none;">VisualBERT: A Simple and Performant Baseline for Vision and Language</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(172).pdf" style="text-decoration:none;">VideoNavQA: Bridging the Gap between
Visual and Embodied Question Answering</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(173).pdf" style="text-decoration:none;">Fusion of Detected Objects in Text for Visual Question Answering</a></li>
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(174).pdf" style="text-decoration:none;">Integrating Multimodal Information in Large Pretrained Transformers</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(175).pdf" style="text-decoration:none;">Unicoder-VL: A Universal Encoder for Vision and Language by Cross-modal Pre-training</a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(176).pdf" style="text-decoration:none;">LXMERT: Learning Cross-Modality Encoder Representations from Transformers</a></li>  
   
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(177).pdf" style="text-decoration:none;">ViCo: Word Embeddings from Visual Co-occurrences</a></li> 
                             
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(178).pdf" style="text-decoration:none;">VL-BERT: Pre-training of Generic Visual-Linguistic Representations</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(179).pdf" style="text-decoration:none;">Towards Unsupervised Image Captioning with Shared Multimodal Embeddings</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(180).pdf" style="text-decoration:none;">Interactive Language Learning by Question Answering</a></li>
                              
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(181).pdf" style="text-decoration:none;">RTFM: Generalising to Novel Environment Dynamics via Reading</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(182).pdf" style="text-decoration:none;">Heterogeneous Graph Learning for Visual
Commonsense Reasoning </a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(183).pdf" style="text-decoration:none;">Few-shot Video-to-Video Synthesis</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(184).pdf" style="text-decoration:none;">Shaping Visual Representations with Language for Few-Shot Classification</a></li>
 
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(185).pdf" style="text-decoration:none;">Dynamic Fusion for Multimodal Data</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(186).pdf" style="text-decoration:none;">Affective Computing for Large-Scale Heterogeneous Multimedia Data: A Survey</a></li>
                             
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(187).pdf" style="text-decoration:none;">Iterative Answer Prediction with Pointer-Augmented Multimodal Transformers for TextVQA</a></li>
                             
  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(188).pdf" style="text-decoration:none;">Two Causal Principles for Improving Visual Dialog</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(189).pdf" style="text-decoration:none;">Self-Supervised Learning by Cross-Modal Audio-Video Clustering</a></li>
    <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(190).pdf" style="text-decoration:none;">12-in-1: Multi-Task Vision and Language Representation Learning</a></li>
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(191).pdf" style="text-decoration:none;">End-to-end facial and physiological model for Affective Computing and applications  </a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(192).pdf" style="text-decoration:none;">A Logical Model for Supporting Social Commonsense Knowledge Acquisition</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(193).pdf" style="text-decoration:none;">Visual Agreement Regularized Training for Multi-Modal Machine Translation</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(194).pdf" style="text-decoration:none;">Towards Learning a Generic Agent for
Vision-and-Language Navigation via Pre-training</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(195).pdf" style="text-decoration:none;">Visual Grounding in Video for UnsupervisedWord Translation</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(196).pdf" style="text-decoration:none;">VIOLIN: A Large-Scale Dataset for Video-and-Language Inference</a></li> 

   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(197).pdf" style="text-decoration:none;">Music Gesture for Visual Sound Separation</a></li> 
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(198).pdf" style="text-decoration:none;">Improving Vision-and-Language Navigation with Image-Text Pairs from the Web</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(199).pdf" style="text-decoration:none;">Unsupervised Multimodal Neural Machine Translation with Pseudo Visual Pivoting</a></li> 
 
  
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(200).pdf" style="text-decoration:none;">The Hateful Memes Challenge:
Detecting Hate Speech in Multimodal Memes</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(201).pdf" style="text-decoration:none;">Multi-agent Communication meets Natural Language: Synergies between Functional and Structural Language Learning</a></li> 
  
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(202).pdf" style="text-decoration:none;">CoMIR: Contrastive Multimodal Image
Representation for Registration</a></li>
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(203).pdf" style="text-decoration:none;">Labelling unlabelled videos
from scratch with multi-modal self-supervision</a></li> 
 
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(204).pdf" style="text-decoration:none;">Self-Supervised MultiModal Versatile Networks</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(205).pdf" style="text-decoration:none;">Towards Debiasing Sentence Representations</a></li>
    <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(206).pdf" style="text-decoration:none;">
Grounded Language Learning Fast and Slow</a></li>                        
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(207).pdf" style="text-decoration:none;">FairCVtest Demo: Understanding Bias in Multimodal Learning with a Testbed in Fair Automatic Recruitment</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(208).pdf" style="text-decoration:none;">Removing Bias in Multi-modal Classifiers: Regularization by Maximizing Functional Entropies</a></li> 
 
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(209).pdf" style="text-decoration:none;">Strategies for Multi-Modal Scene Exploration</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(210).pdf" style="text-decoration:none;">Deep Multimodal Fusion by Channel Exchanging</a></li>


 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(211).pdf" style="text-decoration:none;">Multimodal Transformer for Multimodal Machine Translation</a></li> 
 
 
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(212).pdf" style="text-decoration:none;">What Does BERT with Vision Look At?</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(213).pdf" style="text-decoration:none;">Language to Network: Conditional Parameter Adaptation with Natural Language Descriptions</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(214).pdf" style="text-decoration:none;">Simplifying Coreference Chains for Dyslexic Children</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(215).pdf" style="text-decoration:none;">Multimodal Learning with Deep Boltzmann Machines</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(216).pdf" style="text-decoration:none;">Deep Canonical Correlation Analysis</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(217).pdf" style="text-decoration:none;">Look, Listen and Learn</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(218).pdf" style="text-decoration:none;">Machine Learning in Multimodal Medical Imaging</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(219).pdf" style="text-decoration:none;">Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(220).pdf" style="text-decoration:none;">IEMOCAP: Interactive emotional dyadic motion capture database</a></li>
  
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(221).pdf" style="text-decoration:none;">Is an ImageWorth More than a Thousand Words? On the Fine-Grain Semantic Differences between Visual and Linguistic Representations</a></li>
  <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(222).pdf" style="text-decoration:none;">An empirical study on the effectiveness of images in Multimodal Neural Machine Translation</a></li> 


<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(223).pdf" style="text-decoration:none;">Incorporating Global Visual Features into Attention-Based Neural Machine Translation</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(224).pdf" style="text-decoration:none;">TVQA: Localized, Compositional Video Question Answering</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(225).pdf" style="text-decoration:none;">Adversarial Evaluation of Multimodal Machine Translation</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(226).pdf" style="text-decoration:none;">A Visual Attention Grounding Neural Model for Multimodal Machine Translation</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(227).pdf" style="text-decoration:none;">Collecting Large, Richly Annotated
Facial-Expression Databases from Movies</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(228).pdf" style="text-decoration:none;">See, feel, act: Hierarchical learning for complex manipulation skills with multisensory fusion</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(229).pdf" style="text-decoration:none;">Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(230).pdf" style="text-decoration:none;"> Emergent Communication in a Multi-Modal, Multi-Step Referential Game </a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(231).pdf" style="text-decoration:none;">
Emergent Communication through Negotiation</a></li>
  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(232).pdf" style="text-decoration:none;">Emergent Translation in Multi-Agent Communication</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(233).pdf" style="text-decoration:none;">Stacked Latent Attention for Multimodal Reasoning</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(234).pdf" style="text-decoration:none;">Adventures in Flatland: Perceiving Social Interactions Under Physical Dynamics</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(235).pdf" style="text-decoration:none;">Multi-Modal Scene Understanding
for Robotic Grasping</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Event-Extraction-Papers/blob/master/ev(236).pdf" style="text-decoration:none;">Learning to Separate Object Sounds by Watching Unlabeled Video</a></li>
</ul>
